# **Ερωτήσεις Πολλαπλής Επιλογής**

1.  **Σύμφωνα με το slide 8, γιατί δεν επιλέγουμε απλώς τη μέθοδο με την καλύτερη προσαρμογή στα δεδομένα εκπαίδευσης (π.χ., το μοντέλο "Join-the-dots");**
    *   α. Γιατί είναι πάντα η πιο αργή μέθοδος.
    *   β. Γιατί δεν υπάρχει εγγύηση ότι το μοντέλο θα διατηρήσει την καλή συμπεριφορά σε νέα δεδομένα.
    *   γ. Γιατί απαιτεί πολύπλοκους υπολογισμούς.
    *   δ. Γιατί πάντα οδηγεί σε υποπροσαρμογή (underfitting).

2.  **Ποια από τις παρακάτω μετρικές σφάλματος για προβλήματα παλινδρόμησης είναι πιο ανθεκτική (robust) στις ακραίες τιμές (outliers) (slide 10, 14);**
    *   α. Mean Squared Error (MSE)
    *   β. Root Mean Squared Error (RMSE)
    *   γ. Mean Absolute Error (MAE)
    *   δ. R-Squared

3.  **Γιατί το Mean Squared Error (MSE) είναι συχνά προτιμότερο από το Mean Absolute Error (MAE) για σκοπούς βελτιστοποίησης (slide 10, 11, 14);**
    *   α. Επειδή είναι πάντα μικρότερο.
    *   β. Επειδή είναι πιο εύκολο στην ερμηνεία.
    *   γ. Επειδή είναι παραγωγίσιμη συνάρτηση (differentiable).
    *   δ. Επειδή δεν επηρεάζεται από ακραίες τιμές.

4.  **Ποια είναι η κύρια διαφορά μεταξύ RMSE και MSE (slide 12);**
    *   α. Το RMSE είναι πάντα μεγαλύτερο από το MSE.
    *   β. Το RMSE έχει τις ίδιες μονάδες με την αρχική μεταβλητή απόκρισης, ενώ το MSE όχι.
    *   γ. Το MSE είναι πιο ανθεκτικό στις ακραίες τιμές από το RMSE.
    *   δ. Το RMSE χρησιμοποιείται μόνο για ταξινόμηση.

5.  **Τι σημαίνει μια τιμή R-Squared κοντά στο 1 (slide 13);**
    *   α. Το μοντέλο εξηγεί ένα μεγάλο ποσοστό της μεταβλητότητας της εξαρτημένης μεταβλητής.
    *   β. Το μοντέλο έχει πολύ μεγάλο σφάλμα.
    *   γ. Το μοντέλο είναι πολύ απλό.
    *   δ. Το μοντέλο υποπροσαρμόζεται στα δεδομένα.

6.  **Ποιο είναι ένα μειονέκτημα της μετρικής MAPE (Mean Absolute Percentage Error) (slide 15);**
    *   α. Δεν έχει σαφή ερμηνεία.
    *   β. Δεν είναι ανθεκτική στις ακραίες τιμές.
    *   γ. Είναι απροσδιόριστη όταν οι πραγματικές τιμές είναι μηδέν.
    *   δ. Πάντα υπερεκτιμά την απόδοση του μοντέλου.

7.  **Ποια είναι η κύρια χρησιμότητα της μετρικής MPE (Mean Percentage Error) σε σύγκριση με την MAPE (slide 16);**
    *   α. Είναι πάντα πιο ακριβής.
    *   β. Δείχνει αν το μοντέλο συστηματικά υποεκτιμά ή υπερεκτιμά τις προβλέψεις.
    *   γ. Είναι πιο εύκολη στον υπολογισμό.
    *   δ. Δεν επηρεάζεται από το μέγεθος των σφαλμάτων.

8.  **Ποιο είναι ένα μειονέκτημα της μεθόδου "test set" για την αξιολόγηση μοντέλων (slide 23);**
    *   α. Είναι πολύπλοκη στην εφαρμογή.
    *   β. Δεν παρέχει καμία εκτίμηση για την απόδοση σε νέα δεδομένα.
    *   γ. Σπαταλά δεδομένα (η εκτίμηση αφορά ένα μοντέλο εκπαιδευμένο σε λιγότερα δεδομένα) και η εκτίμηση μπορεί να είναι τυχαία αν το test set είναι μικρό.
    *   δ. Είναι πάντα υπολογιστικά πολύ ακριβή.

9.  **Στην τεχνική Leave-One-Out Cross Validation (LOOCV), πόσες φορές εκπαιδεύεται το μοντέλο αν έχουμε R εγγραφές (slides 24-28);**
    *   α. 1 φορά
    *   β. R φορές
    *   γ. R-1 φορές
    *   δ. 2 φορές

10. **Ποιο είναι το κύριο πλεονέκτημα της LOOCV σε σύγκριση με τη μέθοδο test set (slide 32);**
    *   α. Είναι πολύ πιο γρήγορη.
    *   β. Δεν σπαταλά δεδομένα (χρησιμοποιεί σχεδόν όλα τα δεδομένα για εκπαίδευση σε κάθε επανάληψη).
    *   γ. Είναι λιγότερο ευαίσθητη στη διακύμανση της απόδοσης.
    *   δ. Είναι πάντα πιο αξιόπιστη.

11. **Στην k-fold Cross Validation, πώς χωρίζεται το σύνολο δεδομένων (slide 33);**
    *   α. Σε k+1 τυχαία μέρη (partitions).
    *   β. Σε ένα σύνολο εκπαίδευσης και k σύνολα δοκιμής.
    *   γ. Τυχαία σε k μέρη (folds/partitions).
    *   δ. Σε k επικαλυπτόμενα μέρη.

12. **Ποιο είναι ένα πλεονέκτημα της 10-fold Cross Validation έναντι της LOOCV (R-fold) (slide 40);**
    *   α. Η 10-fold σπαταλά πάντα λιγότερα δεδομένα.
    *   β. Η 10-fold είναι συνήθως υπολογιστικά φθηνότερη από την LOOCV (π.χ., 10 εκπαιδεύσεις αντί για R).
    *   γ. Η 10-fold έχει πάντα μικρότερη διακύμανση στην εκτίμηση του σφάλματος.
    *   δ. Η 10-fold είναι πανομοιότυπη με την LOOCV.

13. **Γιατί οι μετρικές απόδοσης είναι σημαντικές στην μηχανική μάθηση (slide 42);**
    *   α. Βοηθούν στην επιλογή του πιο γρήγορου αλγορίθμου.
    *   β. Αποτυπώνουν έναν επιχειρησιακό στόχο σε έναν ποσοτικό στόχο και βοηθούν στην οργάνωση της προσπάθειας της ομάδας.
    *   γ. Χρησιμοποιούνται μόνο για την εκπαίδευση του μοντέλου.
    *   δ. Εξασφαλίζουν πάντα ότι το μοντέλο δεν θα υπερπροσαρμοστεί.

14. **Στον πίνακα σύγχυσης (Confusion Matrix) για ένα δυαδικό πρόβλημα ταξινόμησης, τι αντιπροσωπεύουν τα False Positives (FP) (slides 46, 49, 51);**
    *   α. Πραγματικά θετικά δείγματα που ταξινομήθηκαν σωστά ως θετικά.
    *   β. Πραγματικά αρνητικά δείγματα που ταξινομήθηκαν λανθασμένα ως θετικά (Σφάλμα Τύπου Ι).
    *   γ. Πραγματικά θετικά δείγματα που ταξινομήθηκαν λανθασμένα ως αρνητικά.
    *   δ. Πραγματικά αρνητικά δείγματα που ταξινομήθηκαν σωστά ως αρνητικά.

15. **Πώς ορίζεται η μετρική "Precision" (Ακρίβεια) (slide 53);**
    *   α. TP / (TP + TN)
    *   β. TP / (TP + FN)
    *   γ. TP / (TP + FP)
    *   δ. TN / (TN + FP)

16. **Τι μετράει η μετρική "Recall" (Ανάκληση) ή "Sensitivity" (Ευαισθησία) (slide 54);**
    *   α. Το ποσοστό των προβλέψεων που είναι σωστές.
    *   β. Από όλα τα δείγματα που προβλέφθηκαν ως θετικά, πόσα ήταν πραγματικά θετικά.
    *   γ. Από όλα τα πραγματικά θετικά δείγματα, πόσα αναγνωρίστηκαν σωστά ως θετικά.
    *   δ. Από όλα τα πραγματικά αρνητικά δείγματα, πόσα αναγνωρίστηκαν σωστά ως αρνητικά.

17. **Γιατί το F1-score είναι συχνά μια χρήσιμη μετρική (slide 56);**
    *   α. Επειδή λαμβάνει υπόψη μόνο τα True Positives.
    *   β. Επειδή είναι ο μέσος όρος της Accuracy και της Precision.
    *   γ. Επειδή παρέχει μια ισορροπία μεταξύ Precision και Recall (είναι ο αρμονικός μέσος τους).
    *   δ. Επειδή είναι πάντα ίσο με την Accuracy.

18. **Ποια από τις παρακάτω μετρικές ΔΕΝ χρησιμοποιείται τυπικά για την αξιολόγηση προβλημάτων συσταδοποίησης (clustering) (slide 61);**
    *   α. Inertia (Within-Cluster Sum of Squares)
    *   β. Silhouette Coefficient
    *   γ. Accuracy
    *   δ. Davies-Bouldin Index

19. **Στην αξιολόγηση της συσταδοποίησης, τι υποδηλώνει μια υψηλή τιμή του Silhouette Coefficient (κοντά στο 1) (slide 61);**
    *   α. Κακή συσταδοποίηση με επικαλυπτόμενες συστάδες.
    *   β. Καλά ορισμένες συστάδες με καλό διαχωρισμό και συνοχή.
    *   γ. Ότι ο αριθμός των συστάδων είναι πολύ μεγάλος.
    *   δ. Ότι τα δεδομένα δεν είναι κατάλληλα για συσταδοποίηση.

20. **Ποια είναι η διαφορά μεταξύ παραμέτρων μοντέλου (model parameters) και υπερπαραμέτρων (hyperparameters) (slides 102, 110);**
    *   α. Οι υπερπαράμετροι μαθαίνονται από τα δεδομένα, ενώ οι παράμετροι μοντέλου ορίζονται από τον χρήστη.
    *   β. Οι παράμετροι μοντέλου ορίζουν την αρχιτεκτονική του μοντέλου, ενώ οι υπερπαράμετροι μετασχηματίζουν τα δεδομένα εισόδου.
    *   γ. Οι παράμετροι μοντέλου (π.χ. βάρη) μαθαίνονται κατά την εκπαίδευση, ενώ οι υπερπαράμετροι (π.χ. ρυθμός μάθησης, αριθμός k γειτόνων) ορίζονται πριν την εκπαίδευση και καθορίζουν τη δομή ή τη διαδικασία μάθησης.
    *   δ. Δεν υπάρχει ουσιαστική διαφορά.

21. **Ποια μέθοδος βελτιστοποίησης υπερπαραμέτρων δοκιμάζει όλους τους πιθανούς συνδυασμούς τιμών από ένα προκαθορισμένο πλέγμα (slide 113, 115);**
    *   α. Manual Search
    *   β. Grid Search
    *   γ. Randomized Search
    *   δ. Bayesian Optimization

22. **Γιατί η Randomized Search μπορεί μερικές φορές να είναι πιο αποτελεσματική από την Grid Search για τη βελτιστοποίηση υπερπαραμέτρων (slide 117);**
    *   α. Επειδή δοκιμάζει πάντα περισσότερους συνδυασμούς.
    *   β. Επειδή δεν όλες οι υπερπαράμετροι είναι εξίσου σημαντικές, και η τυχαία αναζήτηση μπορεί να εξερευνήσει πιο αποδοτικά τις σημαντικές διαστάσεις.
    *   γ. Επειδή είναι πάντα πιο γρήγορη υπολογιστικά.
    *   δ. Επειδή εγγυάται την εύρεση του ολικού βέλτιστου.

23. **Ποια είναι η κύρια ιδέα πίσω από την Bayesian Optimization για υπερπαραμέτρους (slides 118-123);**
    *   α. Δοκιμάζει τυχαίους συνδυασμούς υπερπαραμέτρων.
    *   β. Χτίζει ένα πιθανοθεωρητικό μοντέλο (surrogate model) της αντικειμενικής συνάρτησης και χρησιμοποιεί μια συνάρτηση απόκτησης (acquisition function) για να επιλέξει έξυπνα τις επόμενες υπερπαραμέτρους προς αξιολόγηση.
    *   γ. Αλλάζει χειροκίνητα τις τιμές των υπερπαραμέτρων βασιζόμενη στην εμπειρία.
    *   δ. Χρησιμοποιεί μόνο gradient-based μεθόδους.

24. **Στο πλαίσιο του Hyperparameter Tuning (slide 103), ποιος είναι ο ρόλος του validation set;**
    *   α. Χρησιμοποιείται για την τελική εκτίμηση της απόδοσης του μοντέλου.
    *   β. Χρησιμοποιείται για την εκπαίδευση του μοντέλου μαζί με το training set.
    *   γ. Χρησιμοποιείται για την αξιολόγηση μοντέλων που εκπαιδεύτηκαν με διαφορετικές υπερπαραμέτρους, ώστε να επιλεγεί ο καλύτερος συνδυασμός υπερπαραμέτρων.
    *   δ. Δεν χρησιμοποιείται ποτέ αν υπάρχει test set.

25. **Σύμφωνα με το "Poll 2" (slide 86), τι είναι πιθανό να συμβεί με έναν ταξινομητή 1-Nearest Neighbor;**
    *   α. Overfit (Υπερπροσαρμογή)
    *   β. Underfit (Υποπροσαρμογή)
    *   γ. Ούτε το ένα ούτε το άλλο (είναι ένας εξαιρετικός μαθητής)
    *   δ. Να έχει πάντα την καλύτερη απόδοση.

---

**Απαντήσεις**

1.  **β.** Γιατί δεν υπάρχει εγγύηση ότι το μοντέλο θα διατηρήσει την καλή συμπεριφορά σε νέα δεδομένα.
2.  **γ.** Mean Absolute Error (MAE)
3.  **γ.** Επειδή είναι παραγωγίσιμη συνάρτηση (differentiable).
4.  **β.** Το RMSE έχει τις ίδιες μονάδες με την αρχική μεταβλητή απόκρισης, ενώ το MSE όχι.
5.  **α.** Το μοντέλο εξηγεί ένα μεγάλο ποσοστό της μεταβλητότητας της εξαρτημένης μεταβλητής.
6.  **γ.** Είναι απροσδιόριστη όταν οι πραγματικές τιμές είναι μηδέν.
7.  **β.** Δείχνει αν το μοντέλο συστηματικά υποεκτιμά ή υπερεκτιμά τις προβλέψεις.
8.  **γ.** Σπαταλά δεδομένα (η εκτίμηση αφορά ένα μοντέλο εκπαιδευμένο σε λιγότερα δεδομένα) και η εκτίμηση μπορεί να είναι τυχαία αν το test set είναι μικρό.
9.  **β.** R φορές
10. **β.** Δεν σπαταλά δεδομένα (χρησιμοποιεί σχεδόν όλα τα δεδομένα για εκπαίδευση σε κάθε επανάληψη).
11. **γ.** Τυχαία σε k μέρη (folds/partitions).
12. **β.** Η 10-fold είναι συνήθως υπολογιστικά φθηνότερη από την LOOCV (π.χ., 10 εκπαιδεύσεις αντί για R).
13. **β.** Αποτυπώνουν έναν επιχειρησιακό στόχο σε έναν ποσοτικό στόχο και βοηθούν στην οργάνωση της προσπάθειας της ομάδας.
14. **β.** Πραγματικά αρνητικά δείγματα που ταξινομήθηκαν λανθασμένα ως θετικά (Σφάλμα Τύπου Ι).
15. **γ.** TP / (TP + FP)
16. **γ.** Από όλα τα πραγματικά θετικά δείγματα, πόσα αναγνωρίστηκαν σωστά ως θετικά.
17. **γ.** Επειδή παρέχει μια ισορροπία μεταξύ Precision και Recall (είναι ο αρμονικός μέσος τους).
18. **γ.** Accuracy
19. **β.** Καλά ορισμένες συστάδες με καλό διαχωρισμό και συνοχή.
20. **γ.** Οι παράμετροι μοντέλου (π.χ. βάρη) μαθαίνονται κατά την εκπαίδευση, ενώ οι υπερπαράμετροι (π.χ. ρυθμός μάθησης, αριθμός k γειτόνων) ορίζονται πριν την εκπαίδευση και καθορίζουν τη δομή ή τη διαδικασία μάθησης.
21. **β.** Grid Search
22. **β.** Επειδή δεν όλες οι υπερπαράμετροι είναι εξίσου σημαντικές, και η τυχαία αναζήτηση μπορεί να εξερευνήσει πιο αποδοτικά τις σημαντικές διαστάσεις.
23. **β.** Χτίζει ένα πιθανοθεωρητικό μοντέλο (surrogate model) της αντικειμενικής συνάρτησης και χρησιμοποιεί μια συνάρτηση απόκτησης (acquisition function) για να επιλέξει έξυπνα τις επόμενες υπερπαραμέτρους προς αξιολόγηση.
24. **γ.** Χρησιμοποιείται για την αξιολόγηση μοντέλων που εκπαιδεύτηκαν με διαφορετικές υπερπαραμέτρους, ώστε να επιλεγεί ο καλύτερος συνδυασμός υπερπαραμέτρων.
25. **α.** Overfit (Υπερπροσαρμογή)
