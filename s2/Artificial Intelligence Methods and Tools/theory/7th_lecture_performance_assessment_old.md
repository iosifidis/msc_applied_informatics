# **Performance Assessment** 

---

## 📌 Θεματικές Ενότητες
1. Πρακτικές διασταυρούμενης επικύρωσης (cross-validation)
2. Αξιολόγηση απόδοσης:
   - 📈 Προβλήματα παλινδρόμησης
   - ✅ Προβλήματα ταξινόμησης
   - 🧩 Προβλήματα συσταδοποίησης
3. Παραδείγματα εφαρμογών
4. Βελτιστοποίηση υπερπαραμέτρων (hyperparameter tuning)

---

## 🔁 Cross-Validation

### 📍 Τεστ set (hold-out):
- Διαχωρισμός σε 70% training, 30% test.
- Απλό αλλά "σπαταλά" δεδομένα.

### 📍 Leave-One-Out Cross Validation (LOOCV):
- Εκπαίδευση σε όλα τα σημεία εκτός ενός κάθε φορά.
- Πολύ ακριβές, αλλά ακριβό υπολογιστικά.

### 📍 k-fold CV:
- Χωρίζει τα δεδομένα σε *k* μέρη και κάθε φορά κρατά ένα για έλεγχο.
- Ισορροπία μεταξύ αξιοπιστίας και υπολογιστικού κόστους.
- Συνήθως k=10.

---

## 📊 Αξιολόγηση Παλινδρόμησης

### 📈 Κύριοι Δείκτες:
| Δείκτης | Περιγραφή |
|--------|------------|
| **MAE** (Μέσο απόλυτο σφάλμα) | Ανθεκτικό στους outliers |
| **MSE** (Μέσο τετραγωνικό σφάλμα) | Τονίζει μεγάλα σφάλματα |
| **RMSE** | Εύκολη ερμηνεία (ίδιες μονάδες με το y) |
| **MAPE** | Σφάλμα σε ποσοστά – προσοχή με μηδενικά |
| **R²** (Coefficient of Determination) | Πόσο καλά εξηγεί το μοντέλο τη διακύμανση των δεδομένων |

---

## ✅ Αξιολόγηση Ταξινόμησης

### 🎯 Confusion Matrix:

|               | Actual Positive | Actual Negative |
|---------------|------------------|------------------|
| Predicted Pos | True Positive (TP) | False Positive (FP) |
| Predicted Neg | False Negative (FN) | True Negative (TN) |

### 📌 Δείκτες απόδοσης:
| Δείκτης | Τύπος | Ερμηνεία |
|--------|------|---------|
| **Accuracy** | (TP+TN)/(Σ) | Γενική ακρίβεια |
| **Precision** | TP/(TP+FP) | Ποιότητα θετικών |
| **Recall** (Sensitivity) | TP/(TP+FN) | Ποσοστό ανίχνευσης |
| **Specificity** | TN/(TN+FP) | Ποσοστό αναγνώρισης αρνητικών |
| **F1-score** | 2PR/(P+R) | Ισορροπία Precision & Recall |

---

## 🧩 Αξιολόγηση Clustering

| Δείκτης | Περιγραφή |
|--------|------------|
| **Inertia** | Εσωτερική συνοχή – μικρότερη είναι καλύτερη |
| **Silhouette Coefficient** | Τιμές από -1 έως 1 – πόσο καλά ξεχωρίζουν τα clusters |
| **Davies-Bouldin Index (DBI)** | Μικρότερο = καλύτερος διαχωρισμός |
| **Calinski-Harabasz Index (CHI)** | Μεγαλύτερο = καλύτερη διάκριση μεταξύ ομάδων |

---

## ⚙️ Βελτιστοποίηση Υπερπαραμέτρων

### 📌 Τύποι Υπερπαραμέτρων:
- *max_depth* στο decision tree
- *k* στο k-NN
- *C*, *kernel*, *gamma* στο SVM
- *learning_rate*, *batch_size* στα νευρωνικά

### 📍 Μέθοδοι Επιλογής:
| Μέθοδος | Πλεονεκτήματα | Μειονεκτήματα |
|--------|----------------|----------------|
| **Manual Search** | Απλή | Υποκειμενική |
| **Grid Search** | Συστηματική | Πολύ ακριβή |
| **Random Search** | Γρήγορη | Μπορεί να αγνοήσει καλές επιλογές |
| **Bayesian Optimization** | Έξυπνη αναζήτηση | Πολύπλοκη |

---

## 🔬 Παραδείγματα – Case Studies

### 🌊 Παλινδρόμηση:
- **Πρόβλημα**: Προσομοίωση θαλασσινής διείσδυσης στην Κάλυμνο
- **Αρχιτεκτονικές**: RNN, GRU, LSTM, bi-GRU, bi-LSTM
- **Μετρική**: RMSE

### 🛰️ Ταξινόμηση:
- **Πρόβλημα**: Semantic segmentation σε υπερφασματικές εικόνες
- **Τεχνικές**: Embeddings, propagation σε γράφους
- **Μετρικές**: Accuracy, F1-score

---

## 🎓 Σημαντικά Σχόλια

- Οι **μετρικές δεν είναι πάντα συμφωνημένες**: διαφορετικές μετρικές μπορεί να υποδεικνύουν διαφορετικά “καλύτερα” μοντέλα.
- Ο **συνδυασμός επιλογής κατάλληλων μετρικών + καλών υπερπαραμέτρων** είναι καθοριστικός.
- Το **μέγεθος των δεδομένων** και η **ποικιλία** τους επηρεάζουν την αξιοπιστία των αποτελεσμάτων.

---

Αν θέλεις, μπορώ να δημιουργήσω συνοπτικό **φυλλάδιο επανάληψης**, **πίνακες σύγκρισης μοντέλων**, ή ασκήσεις για αυτοαξιολόγηση. Θα σε ενδιέφερε κάτι τέτοιο για τους φοιτητές;
