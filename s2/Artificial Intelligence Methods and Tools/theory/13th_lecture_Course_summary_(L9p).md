# **Σύνοψη Μαθήματος**

## **Δομή Διάλεξης (Διαφάνεια 2)**

Αυτή η διάλεξη αποτελεί μια σύνοψη των βασικών εννοιών που καλύφθηκαν στο μάθημα, οργανωμένη στις παρακάτω ενότητες:

1.  **Βασικές Αρχές Μηχανικής Μάθησης (Machine Learning Basics):**
    *   Επιβλεπόμενη και Μη Επιβλεπόμενη Μάθηση (Supervised and Unsupervised Learning).
    *   Γραμμικές και Μη-Γραμμικές Μέθοδοι Ταξινόμησης (Linear and Non-linear Classification Methods).
2.  **Εισαγωγή στη Βαθιά Μάθηση (Introduction to Deep Learning).**
3.  **Στοιχεία Νευρωνικών Δικτύων (Elements of Neural Networks - NNs):**
    *   Συναρτήσεις Ενεργοποίησης (Activation Functions).
4.  **Εκπαίδευση Νευρωνικών Δικτύων (Training NNs):**
    *   Κατάβαση Κλίσης (Gradient Descent).
    *   Μέθοδοι Κανονικοποίησης (Regularization Methods).
5.  **Αρχιτεκτονικές Νευρωνικών Δικτύων (NN Architectures):**
    *   Συνελικτικά Νευρωνικά Δίκτυα (Convolutional NNs - CNNs).
    *   Αναδρομικά Νευρωνικά Δίκτυα (Recurrent NNs - RNNs).

### **Ενότητα 1: Βασικές Αρχές Μηχανικής Μάθησης (Διαφάνειες 3-19)**

*   **Ορισμοί (Διαφ. 3):**
    *   **Τεχνητή Νοημοσύνη (Artificial Intelligence - AI):** Επιστημονικό πεδίο που ασχολείται με την ανάπτυξη αλγορίθμων που επιτρέπουν στους υπολογιστές να μαθαίνουν χωρίς να είναι ρητά προγραμματισμένοι.
    *   **Μηχανική Μάθηση (Machine Learning - ML):** Κλάδος της ΤΝ που εστιάζει σε μεθόδους που μαθαίνουν από δεδομένα και κάνουν προβλέψεις σε αόρατα δεδομένα.
    *   **Διαδικασία ML (Διάγραμμα):**
        *   **Εκπαίδευση (Training):** Επισημασμένα Δεδομένα (Labeled Data) -> Αλγόριθμος ML -> Μαθημένο Μοντέλο (Learned Model).
        *   **Πρόβλεψη (Prediction):** Νέα (Επισημασμένα ή μη) Δεδομένα -> Μαθημένο Μοντέλο -> Πρόβλεψη.
*   **Τύποι Μηχανικής Μάθησης (Διαφ. 4):**
    *   **Επιβλεπόμενη Μάθηση (Supervised):** Μάθηση με **επισημασμένα δεδομένα** (δηλαδή, γνωρίζουμε την "απάντηση" για τα δεδομένα εκπαίδευσης).
        *   Παραδείγματα: Ταξινόμηση email (spam/not spam), ταξινόμηση εικόνων.
        *   Παραδείγματα: Παλινδρόμηση (regression) για πρόβλεψη πραγματικών τιμών (π.χ., τιμή σπιτιού).
    *   **Μη Επιβλεπόμενη Μάθηση (Unsupervised):** Ανακάλυψη μοτίβων σε **μη επισημασμένα δεδομένα**.
        *   Παράδειγμα: Ομαδοποίηση (clustering) παρόμοιων σημείων δεδομένων.
    *   **Ενισχυτική Μάθηση (Reinforcement Learning):** Μάθηση δράσης βασισμένη σε **ανατροφοδότηση/ανταμοιβή (feedback/reward)**.
        *   Παράδειγμα: Εκμάθηση παιχνιδιού Go.
    *   **Οπτικά Παραδείγματα:** Ταξινόμηση κειμένου, παλινδρόμηση, ομαδοποίηση.
*   **Κατηγορίες & Τεχνικές Επιβλεπόμενης Μάθησης (Διαφ. 5):**
    *   **Αριθμητικές Συναρτήσεις Ταξινομητή (Numerical classifier functions):** Γραμμικός ταξινομητής, Perceptron, λογιστική παλινδρόμηση, SVMs, νευρωνικά δίκτυα.
    *   **Παραμετρικές (Πιθανοτικές) Συναρτήσεις (Parametric (probabilistic) functions):** Naïve Bayes, GDA, HMMs, πιθανοτικά γραφικά μοντέλα.
    *   **Μη-Παραμετρικές (Βασισμένες σε Περιπτώσεις) Συναρτήσεις (Non-parametric (instance-based) functions):** k-NN, kernel regression, εκτίμηση πυκνότητας πυρήνα, τοπική παλινδρόμηση.
    *   **Συμβολικές Συναρτήσεις (Symbolic functions):** Δέντρα απόφασης, CART.
    *   **Μάθηση Συνόλου (Aggregation (ensemble) learning):** Bagging, boosting (AdaBoost), random forest.
*   **Κατηγορίες & Τεχνικές Μη Επιβλεπόμενης Μάθησης (Διαφ. 6):**
    *   **Ομαδοποίηση (Clustering):** k-means, mean-shift, φασματική ομαδοποίηση.
    *   **Εκτίμηση Πυκνότητας (Density estimation):** Μοντέλα μίξης Γκαουσιανών (GMM), γραφικά μοντέλα.
    *   **Μείωση Διαστατικότητας (Dimensionality reduction):** PCA, παραγοντική ανάλυση.
*   **Ταξινομητής Πλησιέστερου Γείτονα (Nearest Neighbor Classifier) (Διαφ. 7-8):**
    *   **Nearest Neighbor (1-NN):** Για κάθε σημείο δοκιμής, του αναθέτει την ετικέτα κλάσης του πλησιέστερου σημείου εκπαίδευσης.
    *   Απαιτεί μια συνάρτηση απόστασης.
    *   **Δεν απαιτεί εκμάθηση** ενός συνόλου βαρών.
    *   **Για ταξινόμηση εικόνων (Διαφ. 8):** Υπολογισμός απόστασης μεταξύ όλων των pixels (π.χ., L1 ή L2 νόρμα). Παράδειγμα ακρίβειας στο CIFAR-10: 38.6%.
    *   **Μειονεκτήματα:**
        *   Πρέπει να θυμάται όλα τα δεδομένα εκπαίδευσης.
        *   Η ταξινόμηση μιας εικόνας δοκιμής είναι ακριβή (απαιτεί σύγκριση με όλες τις εικόνες εκπαίδευσης).
*   **Ταξινομητής k-Πλησιέστερων Γειτόνων (k-Nearest Neighbors Classifier) (Διαφ. 9):**
    *   Λαμβάνει υπόψη **πολλαπλούς γειτονικούς πόντους** δεδομένων.
    *   Π.χ., για 3-NN, η κλάση του παραδείγματος δοκιμής προκύπτει από **ψηφοφορία** των 3 πλησιέστερων σημείων.
*   **Γραμμικός Ταξινομητής (Linear Classifier) (Διαφ. 10-11):**
    *   Βρίσκει μια γραμμική συνάρτηση `f(xᵢ, W, b) = Wxᵢ + b` που διαχωρίζει τις κλάσεις.
    *   Χρησιμοποιεί ζεύγη εισόδων και ετικετών για να βρει τον πίνακα βαρών **W** και το διάνυσμα πόλωσης (bias) **b**.
    *   Το Perceptron είναι μια μέθοδος εύρεσης αυτών των παραμέτρων.
    *   Αποτελεί δομικό στοιχείο για πιο προηγμένους αλγορίθμους (SVM, NNs).
    *   **Όριο Απόφασης (Decision Boundary) (Διαφ. 11):** Είναι γραμμικό (ευθεία σε 2D, επίπεδο σε 3D, υπερεπίπεδο σε >3D).
    *   Παράδειγμα ταξινόμησης εικόνας γάτας: δείχνει πώς οι παράμετροι W, b χρησιμοποιούνται για να παραχθεί ένα σκορ για κάθε κλάση.
*   **Μηχανές Υποστήριξης Διανυσμάτων (Support Vector Machines - SVM) (Διαφ. 12):**
    *   Στόχος: Να βρεθεί το **βέλτιστο όριο απόφασης**.
    *   Από όλες τις γραμμές που διαχωρίζουν σωστά τις κλάσεις, η γραμμή που είναι **πιο μακριά από όλα τα παραδείγματα εκπαίδευσης** θα έχει καλύτερες ικανότητες γενίκευσης.
    *   Το SVM λύνει ένα πρόβλημα βελτιστοποίησης:
        *   Εντοπίζει ένα όριο απόφασης που ταξινομεί σωστά τα παραδείγματα.
        *   Μεγιστοποιεί το **γεωμετρικό περιθώριο (geometric margin)** μεταξύ του ορίου και όλων των παραδειγμάτων.
        *   Τα σημεία δεδομένων που ορίζουν το μέγιστο περιθώριο ονομάζονται **διανύσματα υποστήριξης (support vectors)**.
        *   Μαθηματική διατύπωση: `min (1/2) ||W||²` υπό τον περιορισμό `yᵢ(W·xᵢ + b) ≥ 1`.
*   **Γραμμικές vs Μη-Γραμμικές Τεχνικές (Διαφ. 13-14):**
    *   **Γραμμικές:** Γραμμικός ταξινομητής, Perceptron, Λογιστική Παλινδρόμηση, Γραμμικό SVM, Naïve Bayes.
    *   **Μη-Γραμμικές:** k-NN, Μη-γραμμικό SVM, Νευρωνικά Δίκτυα, Δέντρα Απόφασης, Random Forest.
    *   **Διαχωρισιμότητα (Διαφ. 14):** Κάποια δεδομένα είναι γραμμικά διαχωρίσιμα. Άλλα όχι, και οι γραμμικοί ταξινομητές δυσκολεύονται.
*   **Μη-Γραμμικές Τεχνικές (Συνέχεια) (Διαφ. 15):**
    *   Τα χαρακτηριστικά `zᵢ` λαμβάνονται ως **μη-γραμμικές συναρτήσεις** των εισόδων `xᵢ`.
    *   Αυτό οδηγεί σε μη-γραμμικά όρια απόφασης.
    *   Παράδειγμα: `Inputs: xᵢ = [xₙ₁, xₙ₂]` -> `Features: zᵢ = [xₙ₁, xₙ₂, xₙ₁·xₙ₂, xₙ₁², xₙ₂²]` -> `Outputs: f(zᵢ, W, b) = Wzᵢ + b`.
*   **Μη-Γραμμικές Μηχανές Υποστήριξης Διανυσμάτων (Non-linear SVM) (Διαφ. 16):**
    *   Ο αρχικός χώρος εισόδου απεικονίζεται σε έναν **χώρο χαρακτηριστικών υψηλότερης διάστασης** όπου το σύνολο εκπαίδευσης είναι γραμμικά διαχωρίσιμο (kernel trick).
    *   Ορίζεται μια μη-γραμμική συνάρτηση πυρήνα (kernel function) για τον υπολογισμό ενός μη-γραμμικού ορίου απόφασης στον αρχικό χώρο χαρακτηριστικών.
*   **Δυαδική vs Πολυ-Κλαδική Ταξινόμηση (Binary vs Multi-class Classification) (Διαφ. 17-18):**
    *   **Δυαδική (Binary):** 2 κλάσεις (π.χ., 0 ή 1, spam/no-spam).
    *   **Πολυ-Κλαδική (Multi-class):** 3 ή περισσότερες κλάσεις.
    *   Και τα δύο προβλήματα μπορούν να είναι γραμμικά ή μη-γραμμικά διαχωρίσιμα (Διαφ. 18).
*   **Εργασίες Όρασης Υπολογιστών (Computer Vision Tasks) (Διαφ. 19):**
    *   **Ταξινόμηση (Classification):** Τι αντικείμενο υπάρχει στην εικόνα; (CAT)
    *   **Ταξινόμηση + Εντοπισμός (Classification + Localization):** Τι αντικείμενο και πού βρίσκεται; (CAT σε ένα πλαίσιο)
    *   **Ανίχνευση Αντικειμένων (Object Detection):** Ποια αντικείμενα και πού βρίσκονται; (CAT, DOG, DUCK σε πολλαπλά πλαίσια)
    *   **Τμηματοποίηση Περιστατικών (Instance Segmentation):** Ποια αντικείμενα, πού βρίσκονται, και ποια pixels ανήκουν σε κάθε αντικείμενο; (CAT, DOG, DUCK με περιγράμματα)
*   **Θεώρημα "No-Free-Lunch" (Διαφ. 20):**
    *   (Wolpert, 2002)
    *   Τα μοντέλα ταξινόμησης είναι απλοποιήσεις της πραγματικότητας, βασισμένες σε ορισμένες υποθέσεις.
    *   **Δεν υπάρχει κανένας μεμονωμένος ταξινομητής που να λειτουργεί καλύτερα για όλα τα πιθανά προβλήματα.**
    *   Χρειάζεται να κάνουμε υποθέσεις για να γενικεύσουμε.

### **Ενότητα 2: Εισαγωγή στη Βαθιά Μάθηση (Διαφάνειες 21-25)**

*   **ML vs. Βαθιά Μάθηση (Deep Learning - DL) (Διαφ. 21-23):**
    *   **Συμβατική ML (Διαφ. 21):** Βασίζεται σε **ανθρώπινα σχεδιασμένες αναπαραστάσεις χαρακτηριστικών (human-designed feature representations)**. Η ML γίνεται απλώς βελτιστοποίηση βαρών για την καλύτερη τελική πρόβλεψη.
        *   Διάγραμμα: Περιγραφή δεδομένων με χαρακτηριστικά (Domain specific) -> Αλγόριθμος Μάθησης (Βελτιστοποίηση βαρών στα χαρακτηριστικά).
    *   **Βαθιά Μάθηση (DL) (Διαφ. 22):** Υποπεδίο της ML που χρησιμοποιεί **πολλαπλά επίπεδα για την εκμάθηση αναπαραστάσεων δεδομένων**.
        *   Εξαιρετικά αποτελεσματική στην εκμάθηση μοτίβων.
        *   Διάγραμμα ML: Είσοδος -> Εξαγωγή Χαρακτηριστικών -> Ταξινόμηση -> Έξοδος.
        *   Διάγραμμα DL: Είσοδος -> (Εξαγωγή Χαρακτηριστικών + Ταξινόμηση μαζί) -> Έξοδος. Η DL μαθαίνει τα χαρακτηριστικά.
    *   **Ιεραρχική Εκμάθηση Χαρακτηριστικών (Διαφ. 23):** Η DL εφαρμόζει μια πολυεπίπεδη διαδικασία για την εκμάθηση πλούσιων ιεραρχικών χαρακτηριστικών.
        *   Pixels εικόνας εισόδου -> Ακμές (Edges) -> Υφές (Textures) -> Μέρη (Parts) -> Αντικείμενα (Objects).
        *   Διάγραμμα: Χαμηλού επιπέδου χαρακτηριστικά -> Μεσαίου επιπέδου -> Υψηλού επιπέδου -> Εκπαιδεύσιμος Ταξινομητής -> Έξοδος.
*   **Γιατί η DL είναι Χρήσιμη; (Διαφ. 24):**
    *   Παρέχει ένα ευέλικτο, μαθησιακό πλαίσιο για την αναπαράσταση οπτικής, κειμενικής, γλωσσικής πληροφορίας.
    *   Μπορεί να μάθει με επιβλεπόμενο και μη επιβλεπόμενο τρόπο.
    *   Αντιπροσωπεύει ένα αποτελεσματικό σύστημα μάθησης **από άκρο σε άκρο (end-to-end)**.
    *   Απαιτεί μεγάλες ποσότητες δεδομένων εκπαίδευσης.
    *   Από το 2010 περίπου, η DL έχει ξεπεράσει άλλες τεχνικές ML (πρώτα στην όραση και ομιλία, μετά στο NLP και άλλες εφαρμογές).
*   **Αναπαραστασιακή Ισχύς (Representational Power) (Διαφ. 25):**
    *   Νευρωνικά Δίκτυα (NNs) με τουλάχιστον ένα κρυφό επίπεδο είναι **καθολικοί προσεγγιστές (universal approximators)**.
        *   Δεδομένης οποιασδήποτε συνεχούς συνάρτησης `h(x)` και κάποιου `ε > 0`, υπάρχει ένα ΝΝ με ένα κρυφό επίπεδο (και λογική επιλογή μη-γραμμικότητας) που περιγράφεται με τη συνάρτηση `f(x)`, τέτοιο ώστε `∀x, |h(x) - f(x)| < ε`.
        *   Δηλαδή, ένα ΝΝ μπορεί να προσεγγίσει οποιαδήποτε αυθαίρετα πολύπλοκη συνεχή συνάρτηση.
    *   Τα NNs χρησιμοποιούν μη-γραμμική απεικόνιση των εισόδων `x` στις εξόδους `f(x)` για τον υπολογισμό πολύπλοκων ορίων απόφασης.
    *   **Γιατί τότε βαθύτερα NNs;**
        *   Το γεγονός ότι τα βαθιά NNs λειτουργούν καλύτερα είναι μια **εμπειρική παρατήρηση**.
        *   Μαθηματικά, τα βαθιά NNs έχουν την ίδια αναπαραστασιακή ισχύ με ένα ΝΝ ενός επιπέδου (με αρκετούς νευρώνες). Ωστόσο, τα βαθιά δίκτυα μπορούν να μάθουν τις ίδιες συναρτήσεις πιο **αποτελεσματικά** (με λιγότερες παραμέτρους) και να γενικεύουν καλύτερα.

### **Ενότητα 3: Στοιχεία Νευρωνικών Δικτύων (NNs) (Διαφάνειες 26-45)**

*   **Εισαγωγή στα Νευρωνικά Δίκτυα (Διαφ. 26-27):**
    *   Παράδειγμα: Αναγνώριση χειρόγραφων ψηφίων (MNIST dataset).
    *   Η ένταση κάθε pixel θεωρείται στοιχείο εισόδου.
    *   Η έξοδος είναι η κλάση του ψηφίου.
    *   **Είσοδος (Διαφ. 26):** Εικόνα 16x16 = 256 pixels. Κάθε pixel `xᵢ` είναι μια τιμή.
    *   **Έξοδος (Διαφ. 26):** 10 διαστάσεις (για ψηφία 0-9). Κάθε διάσταση `yᵢ` αντιπροσωπεύει την "πεποίθηση" (confidence) ότι η εικόνα είναι το ψηφίο `i`.
    *   Το μηχάνημα (ένα νευρωνικό δίκτυο) αναπαριστά τη συνάρτηση `f: R²⁵⁶ → R¹⁰` (Διαφ. 27).
*   **Στοιχεία Νευρωνικών Δικτύων (Διαφ. 28):**
    *   Τα NNs αποτελούνται από κρυφά επίπεδα με νευρώνες (υπολογιστικές μονάδες).
    *   Ένας **μεμονωμένος νευρώνας** απεικονίζει ένα σύνολο εισόδων σε έναν αριθμό εξόδου:
        *   `z = a₁w₁ + a₂w₂ + ... + aKWK + b` (σταθμισμένο άθροισμα εισόδων `aᵢ` με βάρη `wᵢ` συν πόλωση `b`).
        *   `a = σ(z)` (η έξοδος `a` του νευρώνα είναι η ενεργοποίηση `σ` του `z`).
*   **ΝΝ με ένα κρυφό επίπεδο και ένα επίπεδο εξόδου (Διαφ. 29):**
    *   Διάγραμμα που δείχνει επίπεδο εισόδου (`x`), κρυφό επίπεδο (`h`), επίπεδο εξόδου (`y`).
    *   `hidden layer h = σ(W₁x + b₁)`
    *   `output layer y = σ(W₂h + b₂)`
    *   Υπολογισμός μαθησιακών παραμέτρων: #νευρώνες (χωρίς εισόδους), #βάρη, #πόλωσεις.
*   **Παιχνιδότοπος Νευρωνικών Δικτύων (Neural Network Playground) (Διαφ. 30):** Σύνδεσμος προς το [playground.tensorflow.org](http://playground.tensorflow.org).
*   **Βαθιά NNs (Διαφ. 31):**
    *   Έχουν πολλά κρυφά επίπεδα.
    *   **Πλήρως Συνδεδεμένα (dense) Επίπεδα (Fully-connected layers / Multi-Layer Perceptron - MLP):** Κάθε νευρώνας συνδέεται με όλους τους νευρώνες του επόμενου επιπέδου.
*   **Παράδειγμα Λειτουργίας Απλού Δικτύου (Διαφ. 32-33):**
    *   Δίκτυο με 2 εισόδους, 2 νευρώνες στο πρώτο (κρυφό) επίπεδο, 2 νευρώνες στο επίπεδο εξόδου.
    *   Χρήση της **σιγμοειδούς συνάρτησης (Sigmoid Function)** ως συνάρτηση ενεργοποίησης: `σ(z) = 1 / (1 + e⁻ᶻ)`.
    *   Δείχνει βήμα-βήμα τον υπολογισμό των εξόδων.
*   **Λειτουργία Πινάκων (Matrix Operation) (Διαφ. 34-37):**
    *   Οι λειτουργίες πινάκων είναι χρήσιμες για πολυδιάστατες εισόδους/εξόδους.
    *   Το παράδειγμα της διαφ. 32 μπορεί να γραφτεί ως `σ(Wx + b) = a` (Διαφ. 34).
    *   Υπολογισμοί για το πρώτο επίπεδο πολυεπίπεδου ΝΝ (Διαφ. 35): `a¹ = σ(W¹x + b¹)`.
    *   Υπολογισμοί για όλα τα επίπεδα (Διαφ. 36): Διαδοχικές εφαρμογές `aˡ = σ(Wˡaˡ⁻¹ + bˡ)`.
    *   Συνολική συνάρτηση `y = f(x)` (Διαφ. 37).
*   **Επίπεδο Softmax (Softmax Layer) (Διαφ. 38-39):**
    *   Σε εργασίες **πολυ-κλαδικής ταξινόμησης (multi-class classification)**, το επίπεδο εξόδου είναι τυπικά ένα επίπεδο Softmax.
    *   Χρησιμοποιεί τη **συνάρτηση ενεργοποίησης Softmax**.
    *   Αν χρησιμοποιηθεί σιγμοειδής, οι προβλέψεις μπορεί να μην είναι εύκολο να ερμηνευτούν ως πιθανότητες.
    *   **Σιγμοειδής Έξοδος (Διαφ. 38):** Οι έξοδοι `yᵢ = σ(zᵢ)` δεν αθροίζουν στο 1.
    *   **Softmax Έξοδος (Διαφ. 39):** Οι τιμές `z` (logits) μετατρέπονται σε πιθανότητες:
        `yᵢ = eᶻᵢ / Σⱼ eᶻⱼ`
        *   Οι έξοδοι `yᵢ` είναι στο εύρος [0, 1].
        *   Το άθροισμα όλων των `yᵢ` είναι 1 (`Σ yᵢ = 1`).
*   **Συναρτήσεις Ενεργοποίησης (Activation Functions) (Διαφ. 40-45):**
    *   **Μη-γραμμικές ενεργοποιήσεις (Non-linear activations)** είναι απαραίτητες για την εκμάθηση πολύπλοκων (μη-γραμμικών) αναπαραστάσεων δεδομένων. Αλλιώς, τα NNs θα ήταν απλώς γραμμικές συναρτήσεις.
    *   NNs με πολλά επίπεδα (και νευρώνες) μπορούν να προσεγγίσουν πιο πολύπλοκες συναρτήσεις (αλλά μπορεί να υπερπροσαρμοστούν).
    *   **Sigmoid (Διαφ. 41):** "Συνθλίβει" έναν πραγματικό αριθμό στο εύρος [0, 1]. Μπορεί να ερμηνευθεί ως ρυθμός πυροδότησης νευρώνα. Προβλήματα: κορεσμός (saturation) όταν οι ενεργοποιήσεις είναι 0 ή 1, οδηγώντας σε μηδενικές κλίσεις (vanishing gradients). Λιγότερο συχνή σε σύγχρονα NNs.
    *   **Tanh (Υπερβολική Εφαπτομένη) (Διαφ. 42):** "Συνθλίβει" στο εύρος [-1, 1]. Όπως η sigmoid, κορέννυται. Σε αντίθεση με τη sigmoid, η έξοδος είναι **μηδενικο-κεντρική (zero-centered)**, κάτι που συχνά προτιμάται. Είναι μια κλιμακωμένη sigmoid.
    *   **ReLU (Rectified Linear Unit) (Διαφ. 43):** `f(x) = max(0, x)`. Παίρνει έναν πραγματικό αριθμό και τον θέτει σε μηδέν αν είναι αρνητικός.
        *   Χρησιμοποιείται στα περισσότερα σύγχρονα βαθιά NNs.
        *   Γρήγορη στον υπολογισμό.
        *   Επιταχύνει τη σύγκλιση της κατάβασης κλίσης (λόγω γραμμικής, μη-κορεσμένης μορφής για x > 0).
        *   **Αποτρέπει το πρόβλημα της εξαφανιζόμενης κλίσης (gradient vanishing problem)** (για x > 0).
    *   **Leaky ReLU (Διαφ. 44):** Παραλλαγή της ReLU. Αντί για 0 όταν `x < 0`, έχει μια μικρή αρνητική κλίση (π.χ., `α = 0.01`).
        *   Πρόβλημα "Dying ReLU": Ένας ReLU νευρώνας μπορεί να "πεθάνει" (να μην ενεργοποιείται ποτέ ξανά) αν οι κλίσεις γίνουν μηδέν (π.χ., με μεγάλο learning rate).
        *   Η Leaky ReLU επιλύει αυτό το πρόβλημα.
    *   **Γραμμική Συνάρτηση (Linear Function) (Διαφ. 45):** `f(x) = cx`. Η έξοδος είναι ανάλογη της εισόδου.
        *   Αν `c=1`, ονομάζεται **ταυτοτική συνάρτηση ενεργοποίησης (identity activation function)**.
        *   Χρησιμοποιείται σε προβλήματα παλινδρόμησης (π.χ., το τελευταίο επίπεδο μπορεί να έχει γραμμική ενεργοποίηση για να εξάγει έναν πραγματικό αριθμό).

### **Ενότητα 4: Εκπαίδευση Νευρωνικών Δικτύων (NNs) (Διαφάνειες 46-84)**

*   **Παράμετροι Δικτύου (Διαφ. 46):** Οι παράμετροι `θ` περιλαμβάνουν τους πίνακες βαρών (weight matrices) και τα διανύσματα πόλωσης (bias vectors) από όλα τα επίπεδα. Συχνά αναφέρονται απλώς ως "βάρη".
*   **Προεπεξεργασία Δεδομένων (Data Preprocessing) (Διαφ. 47):** Βοηθά στη σύγκλιση κατά την εκπαίδευση.
    *   **Αφαίρεση Μέσου (Mean subtraction):** Για μηδενικο-κεντρικά δεδομένα.
    *   **Κανονικοποίηση (Normalization):** Διαίρεση με την τυπική απόκλιση (για μοναδιαία τυπική απόκλιση) ή κλιμάκωση στο [0,1] ή [-1,1].
*   **Στόχος Εκπαίδευσης (Διαφ. 48):** Να οριστούν οι παράμετροι `θ` έτσι ώστε για ένα υποσύνολο εκπαίδευσης εικόνων, τα αντίστοιχα στοιχεία στην προβλεπόμενη έξοδο να έχουν μέγιστες τιμές (π.χ., για την εικόνα "1", το `y₁` να είναι μέγιστο).
*   **Συνάρτηση Απώλειας (Loss Function) (Διαφ. 49-50):**
    *   Ορίζεται μια συνάρτηση απώλειας/κόστους `L(θ)` που υπολογίζει τη διαφορά (σφάλμα) μεταξύ της πρόβλεψης του μοντέλου και της αληθινής ετικέτας.
    *   Παραδείγματα: Μέσο τετραγωνικό σφάλμα (MSE), διασταυρούμενη εντροπία (cross-entropy).
    *   **Συνολική Απώλεια (Διαφ. 50):** Για ένα σύνολο εκπαίδευσης Ν εικόνων, υπολογίζεται η συνολική απώλεια `L(θ) = Σ Lₙ(θ)`.
    *   Στόχος: Να βρεθούν οι βέλτιστες παράμετροι `θ*` που **ελαχιστοποιούν** τη συνολική απώλεια `L(θ)`.
*   **Συναρτήσεις Απώλειας (Συνέχεια) (Διαφ. 51-52):**
    *   **Εργασίες Ταξινόμησης (Διαφ. 51):**
        *   **Cross-entropy:** `L(θ) = -(1/N) Σᵢ Σₖ [y^{(k)}ᵢ log ŷ^{(k)}ᵢ + (1 - y^{(k)}ᵢ) log(1 - ŷ^{(k)}ᵢ)]` (για δυαδική, ή γενικότερα για Softmax με one-hot ετικέτες).
    *   **Εργασίες Παλινδρόμησης (Διαφ. 52):**
        *   **Mean Squared Error (MSE):** `L(θ) = (1/n) Σ (y⁽ⁱ⁾ - ŷ⁽ⁱ⁾)²`
        *   **Mean Absolute Error (MAE):** `L(θ) = (1/n) Σ |y⁽ⁱ⁾ - ŷ⁽ⁱ⁾|`
*   **Κατάβαση Κλίσης (Gradient Descent - GD) (Διαφ. 53-58):**
    *   Αλγόριθμος βελτιστοποίησης για την ελαχιστοποίηση της `L(θ)`.
    *   Εφαρμόζει επαναληπτική βελτίωση των παραμέτρων `θ`.
    *   Χρησιμοποιεί την **αντίθετη κατεύθυνση της κλίσης (gradient)** της απώλειας ως προς τις παραμέτρους για την ενημέρωση του `θ`. Η κλίση `∇L(θ)` δείχνει την κατεύθυνση της ταχύτερης αύξησης της απώλειας.
    *   **Βήματα Αλγορίθμου (Διαφ. 54):**
        1.  Τυχαία αρχικοποίηση παραμέτρων `θ⁰`.
        2.  Υπολογισμός κλίσης `∇L(θ⁰)`.
        3.  Ενημέρωση παραμέτρων: `θ_new = θ⁰ - α∇L(θ⁰)` (όπου `α` ο ρυθμός μάθησης).
        4.  Επανάληψη από το βήμα 2.
    *   **Οπτικοποίηση (Διαφ. 55-56):** Παράδειγμα με 2 παραμέτρους. Οι ισοϋψείς καμπύλες δείχνουν την τιμή της απώλειας. Η κατάβαση κλίσης ακολουθεί την κατεύθυνση της μεγαλύτερης πτώσης.
    *   **Τοπικά vs Ολικά Ελάχιστα (Διαφ. 57-58):**
        *   Ο GD σταματά όταν φτάσει σε ένα **τοπικό ελάχιστο (local minimum)**.
        *   Δεν εγγυάται την εύρεση του **ολικού ελαχίστου (global minimum)**.
        *   Ωστόσο, εμπειρικά, ο GD λειτουργεί καλά για NNs.
        *   Η επιφάνεια απώλειας είναι συνήθως πολύπλοκη και μη-κυρτή. Η τυχαία αρχικοποίηση οδηγεί σε διαφορετικά τοπικά ελάχιστα.
*   **Οπισθοδιάδοση (Backpropagation) (Διαφ. 59):**
    *   Μέθοδος για τον υπολογισμό των κλίσεων `∇L(θ)`.
    *   **Προώθηση Εμπρός (Forward propagation):** Πέρασμα των εισόδων `x` μέσω των επιπέδων για λήψη των εξόδων `ŷ`. Υπολογισμός απώλειας `L(y,ŷ)`.
    *   **Οπισθοδιάδοση (Backpropagation):** Διάβαση του δικτύου αντίστροφα (από εξόδους προς εισόδους) για τον υπολογισμό των κλίσεων της απώλειας ως προς τις παραμέτρους `θ` κάθε επιπέδου, χρησιμοποιώντας τον κανόνα της αλυσίδας (chain rule).
    *   **Αυτόματη Διαφοροποίηση (Automatic differentiation):** Διαθέσιμη σε όλες τις σύγχρονες βιβλιοθήκες βαθιάς μάθησης.
*   **Mini-batch Gradient Descent (Διαφ. 60):**
    *   Είναι αναποτελεσματικό να υπολογίζουμε την απώλεια πάνω σε ολόκληρο το σύνολο εκπαίδευσης για κάθε ενημέρωση παραμέτρων (ειδικά για μεγάλα σύνολα).
    *   **Προσέγγιση:** Υπολογισμός της απώλειας και της κλίσης σε μια μικρή παρτίδα (mini-batch) εικόνων, ενημέρωση παραμέτρων, επανάληψη.
    *   Πολύ ταχύτερη εκπαίδευση. Τυπικό μέγεθος mini-batch: 32 έως 256.
    *   Λειτουργεί γιατί η κλίση από ένα mini-batch είναι καλή προσέγγιση της κλίσης από ολόκληρο το σύνολο.
*   **Στοχαστική Κατάβαση Κλίσης (Stochastic Gradient Descent - SGD) (Διαφ. 61):**
    *   Χρησιμοποιεί mini-batches που αποτελούνται από **ένα μόνο παράδειγμα εισόδου**.
    *   Πολύ γρήγορη, αλλά μπορεί να προκαλέσει σημαντικές διακυμάνσεις στη συνάρτηση απώλειας.
    *   Στις περισσότερες βιβλιοθήκες DL, "SGD" τυπικά σημαίνει mini-batch GD (με επιλογή για momentum).
*   **Προβλήματα με την Κατάβαση Κλίσης (Διαφ. 62):**
    *   Εκτός από τα τοπικά ελάχιστα, ο GD μπορεί να είναι πολύ αργός σε **πλατώ (plateaus)** (περιοχές όπου η κλίση είναι σχεδόν μηδέν) και μπορεί να κολλήσει σε **σημεία σέλας (saddle points)**.
*   **Κατάβαση Κλίσης με Ορμή (Gradient Descent with Momentum) (Διαφ. 63-64):**
    *   Χρησιμοποιεί την "ορμή" της κλίσης για βελτιστοποίηση παραμέτρων.
    *   **Κίνηση = - (Αρνητικό της Κλίσης) + Ορμή**. Βοηθά να ξεπεραστούν μικρά τοπικά ελάχιστα και πλατώ.
    *   **Ενημέρωση Παραμέτρων (Διαφ. 64):** `θᵗ = θᵗ⁻¹ - Vᵗ`
        *   `Vᵗ = βVᵗ⁻¹ + α∇L(θᵗ⁻¹)` (όπου `Vᵗ` είναι η ορμή, `β` ο συντελεστής ορμής, συνήθως 0.9).
    *   Η ορμή συσσωρεύει τις κλίσεις από προηγούμενα βήματα.
*   **Nesterov Accelerated Momentum (Διαφ. 65):**
    *   Παραλλαγή του momentum. "Κοιτάζει μπροστά" υπολογίζοντας την κλίση στην "προβλεπόμενη" μελλοντική θέση.
*   **Adam (Adaptive Moment Estimation) (Διαφ. 66):**
    *   Συνδυάζει ιδέες από βελτιστοποιητές ορμής και εισάγει όρους βασισμένους στη δεύτερη ροπή της κλίσης.
    *   Υπολογίζει σταθμισμένους μέσους όρους προηγούμενων κλίσεων (1η ροπή) και τετραγώνων κλίσεων (2η ροπή).
    *   Προσαρμόζει τον ρυθμό μάθησης για κάθε παράμετρο ξεχωριστά.
    *   Πολύ δημοφιλής βελτιστοποιητής.
*   **Ρυθμός Μάθησης (Learning Rate) (Διαφ. 67-68):**
    *   Η κλίση μας λέει την κατεύθυνση, αλλά όχι πόσο μακριά να κινηθούμε.
    *   Η επιλογή του ρυθμού μάθησης (step size) είναι κρίσιμη υπερ-παράμετρος.
    *   **Μικρό LR:** Αργή σύγκλιση. **Μεγάλο LR:** Η απώλεια μπορεί να αυξηθεί ή να ταλαντωθεί.
*   **Προγραμματισμός Ρυθμού Μάθησης (Learning Rate Scheduling) (Διαφ. 69):**
    *   Αλλαγή των τιμών του ρυθμού μάθησης κατά την εκπαίδευση.
    *   **Ανόπτηση (Annealing / Learning Rate Decay):** Μείωση του LR με την πάροδο του χρόνου.
        *   Π.χ., μείωση κατά έναν παράγοντα κάθε λίγες εποχές, εκθετική/cosine φθορά, μείωση όταν η απώλεια επικύρωσης σταματά να βελτιώνεται.
    *   **Προθέρμανση (Warmup):** Σταδιακή αύξηση του LR αρχικά, και μετά μείωση.
*   **Πρόβλημα Εξαφανιζόμενης/Εκρηγνυόμενης Κλίσης (Vanishing/Exploding Gradient Problem) (Διαφ. 70):**
    *   Οι κλίσεις μπορεί να γίνουν πολύ μικρές (vanishing) ή πολύ μεγάλες (exploding), οδηγώντας σε πολύ μικρές/μεγάλες ενημερώσεις παραμέτρων.
    *   Λύσεις: Αλλαγή LR, ReLU, κανονικοποίηση, LSTM μονάδες σε RNNs.
*   **Γενίκευση (Generalization) (Διαφ. 71):**
    *   **Υποπροσαρμογή (Underfitting):** Το μοντέλο είναι πολύ "απλό". Υψηλό σφάλμα σε εκπαίδευση και επικύρωση.
    *   **Υπερπροσαρμογή (Overfitting):** Το μοντέλο είναι πολύ "πολύπλοκο", ταιριάζει στον θόρυβο. Χαμηλό σφάλμα εκπαίδευσης, υψηλό σφάλμα επικύρωσης.
*   **Υπερπροσαρμογή (Overfitting) (Συνέχεια) (Διαφ. 72):**
    *   Ένα μοντέλο με υψηλή χωρητικότητα προσαρμόζεται στον θόρυβο των δεδομένων αντί για την υποκείμενη σχέση.
    *   Μπορεί να ταιριάζει πολύ καλά στα δεδομένα εκπαίδευσης, αλλά αποτυγχάνει να γενικεύσει σε νέα δεδομένα.
*   **Κανονικοποίηση: Φθορά Βαρών (Regularization: Weight Decay) (Διαφ. 73-75):**
    *   **ℓ₂ weight decay (Διαφ. 73):** Ένας όρος κανονικοποίησης που τιμωρεί μεγάλα βάρη προστίθεται στη συνάρτηση απώλειας: `L_reg(θ) = L(θ) + λ Σ θ²_k`.
    *   Ο συντελεστής φθοράς βαρών `λ` καθορίζει την κυριαρχία της κανονικοποίησης.
    *   **Επίδραση του `λ` (Διαφ. 74):** Μεγαλύτερο `λ` -> μεγαλύτερη ποινή για μεγάλα βάρη -> πιο ομαλά όρια απόφασης.
    *   **ℓ₁ weight decay (Διαφ. 75):** Βασίζεται στην ℓ₁ νόρμα των βαρών: `L_reg(θ) = L(θ) + λ Σ |θ_k|`. Οδηγεί σε αραιότητα (πολλά βάρη γίνονται μηδέν). Λιγότερο συνηθισμένο.
    *   **Elastic Net Regularization:** Συνδυασμός ℓ₁ και ℓ₂.
*   **Κανονικοποίηση: Dropout (Διαφ. 76-77):**
    *   Τυχαία "απόρριψη" μονάδων (και των συνδέσεών τους) κατά την εκπαίδευση.
    *   Κάθε μονάδα διατηρείται με πιθανότητα `p` (dropout rate).
    *   Σαν να εκπαιδεύουμε ένα σύνολο (ensemble) από ελαφρώς διαφορετικές αρχιτεκτονικές (Διαφ. 77).
*   **Κανονικοποίηση: Πρόωρη Διακοπή (Early Stopping) (Διαφ. 78):**
    *   Κατά την εκπαίδευση, παρακολουθούμε την απόδοση (π.χ., ακρίβεια ή απώλεια) σε ένα σύνολο επικύρωσης.
    *   Σταματάμε την εκπαίδευση όταν η απόδοση στο σύνολο επικύρωσης δεν βελτιώνεται για `n` εποχές (patience).
*   **Κανονικοποίηση Παρτίδας (Batch Normalization) (Διαφ. 79):**
    *   Επίπεδα που δρουν παρόμοια με την προεπεξεργασία δεδομένων.
    *   Υπολογίζουν τον μέσο `μ` και τη διακύμανση `σ` μιας παρτίδας δεδομένων εισόδου, και κανονικοποιούν τα δεδομένα `x` σε μηδενικό μέσο και μοναδιαία διακύμανση: `x̂ = (x - μ) / σ`.
    *   Αμβλύνουν προβλήματα αρχικοποίησης και υπερ-παραμέτρων.
    *   Ταχύτερη σύγκλιση, επιτρέπουν μεγαλύτερους ρυθμούς μάθησης.
    *   Μειώνουν την εσωτερική μετατόπιση συνδιακύμανσης (internal covariate shift).
    *   Εισάγονται αμέσως μετά από συνελικτικά/πλήρως συνδεδεμένα επίπεδα και πριν από τα επίπεδα ενεργοποίησης.
*   **Ρύθμιση Υπερ-παραμέτρων (Hyper-parameter Tuning) (Διαφ. 80-81):**
    *   **Κοινές Υπερ-παράμετροι (Διαφ. 80):** Αριθμός επιπέδων/νευρώνων, αρχικός LR, πρόγραμμα μείωσης LR, τύπος βελτιστοποιητή.
    *   **Άλλες (Διαφ. 80):** Παράμετροι κανονικοποίησης, μέγεθος παρτίδας, συναρτήσεις ενεργοποίησης, συνάρτηση απώλειας.
    *   **Μέθοδοι Ρύθμισης (Διαφ. 81):**
        *   **Grid Search:** Έλεγχος όλων των τιμών σε ένα εύρος με ένα βήμα.
        *   **Random Search:** Τυχαία δειγματοληψία τιμών. Συχνά προτιμάται.
        *   **Bayesian Hyper-parameter Optimization:** Ενεργός τομέας έρευνας.
*   **k-Fold Cross-Validation (Διαφ. 82-83):**
    *   Χρήσιμο όταν το μέγεθος των δεδομένων εκπαίδευσης είναι μικρό.
    *   Καλύτερη και λιγότερο θορυβώδης εκτίμηση της απόδοσης του μοντέλου.
    *   Παράδειγμα 5-fold: Χωρισμός δεδομένων εκπαίδευσης σε 5 τμήματα. Χρήση 4 για εκπαίδευση, 1 για επικύρωση, επανάληψη 5 φορές. Υπολογισμός μέσου όρου αποτελεσμάτων.
*   **Μάθηση Συνόλου (Ensemble Learning) (Διαφ. 84):**
    *   Εκπαίδευση πολλαπλών ταξινομητών ξεχωριστά και συνδυασμός των προβλέψεών τους.
    *   Συχνά ξεπερνά μεμονωμένους ταξινομητές.
    *   **Bagging (Bootstrap Aggregating):** Τυχαία υποσύνολα δεδομένων εκπαίδευσης, εκπαίδευση ταξινομητή σε κάθε υποσύνολο, μέσος όρος ψήφων.
    *   **Boosting:** Εκπαίδευση ταξινομητή, εφαρμογή βαρών στα δεδομένα (μεγαλύτερα βάρη σε λανθασμένα ταξινομημένα παραδείγματα), εκπαίδευση νέου ταξινομητή, επανάληψη.

### **Ενότητα 5: Αρχιτεκτονικές Νευρωνικών Δικτύων (NNs) (Διαφάνειες 85-97)**

*   **Βαθιά vs Ρηχά Δίκτυα (Deep vs Shallow Networks) (Διαφ. 85):**
    *   Τα βαθύτερα δίκτυα αποδίδουν καλύτερα από τα ρηχά.
    *   Μόνο μέχρι ένα σημείο: μετά από έναν ορισμένο αριθμό επιπέδων, η απόδοση των βαθύτερων δικτύων σταθεροποιείται (plateaus).
*   **Συνελικτικά Νευρωνικά Δίκτυα (Convolutional Neural Networks - CNNs) (Διαφ. 86-91):**
    *   Σχεδιασμένα κυρίως για δεδομένα εικόνας.
    *   Χρησιμοποιούν έναν **συνελικτικό τελεστή (convolutional operator)** για εξαγωγή χαρακτηριστικών.
    *   **Πλεονεκτήματα (Διαφ. 86):**
        *   Επιτρέπουν **κοινή χρήση παραμέτρων (parameter sharing)** (το ίδιο φίλτρο εφαρμόζεται παντού).
        *   Αποδοτικά στην εκπαίδευση.
        *   Έχουν **λιγότερες παραμέτρους** από NNs με πλήρως συνδεδεμένα επίπεδα.
    *   Είναι **ανθεκτικά σε χωρικές μετατοπίσεις (spatial translations)** αντικειμένων.
    *   Ένα συνελικτικό φίλτρο "γλιστράει" (συνελίσσεται) κατά μήκος της εικόνας.
    *   **Ανίχνευση Χαρακτηριστικών (Διαφ. 87):** Τα συνελικτικά φίλτρα συλλαμβάνουν χρήσιμα χαρακτηριστικά (π.χ., ανίχνευση ακμών).
    *   **Τοπικό Αντιληπτικό Πεδίο (Local Receptive Field) (Διαφ. 88):** Οι κρυφές μονάδες σε ένα επίπεδο συνδέονται μόνο με μια μικρή περιοχή του προηγούμενου επιπέδου.
    *   Το βάθος κάθε feature map αντιστοιχεί στον αριθμό των συνελικτικών φίλτρων που χρησιμοποιήθηκαν.
    *   **Max Pooling / Average Pooling (Διαφ. 89):** Μειώνουν το χωρικό μέγεθος των feature maps (μείωση παραμέτρων, πρόληψη overfitting).
    *   **Αρχιτεκτονική Εξαγωγής Χαρακτηριστικών (Διαφ. 90):** Τυπική ροή: Συνελικτικά επίπεδα -> Max-pooling -> Πλήρως συνδεδεμένα επίπεδα + Softmax.
    *   **Υπολειμματικά CNNs (Residual CNNs - ResNets) (Διαφ. 91):** Εισάγουν "ταυτοτικές" συνδέσεις παράκαμψης (skip connections). Βοηθούν στην εκπαίδευση πολύ βαθιών δικτύων, μετριάζοντας το πρόβλημα των εξαφανιζόμενων κλίσεων.
*   **Αναδρομικά Νευρωνικά Δίκτυα (Recurrent Neural Networks - RNNs) (Διαφ. 92-97):**
    *   Χρησιμοποιούνται για μοντελοποίηση **ακολουθιακών δεδομένων (sequential data)** και δεδομένων με μεταβαλλόμενο μήκος εισόδων/εξόδων (π.χ., βίντεο, κείμενο, ομιλία).
    *   Εισάγουν **αναδρομικές συνδέσεις (recurrent connections)** μεταξύ των νευρώνων.
    *   Επιτρέπουν την επεξεργασία ακολουθιακών δεδομένων ένα στοιχείο τη φορά, περνώντας επιλεκτικά πληροφορίες κατά μήκος της ακολουθίας.
    *   Η **μνήμη των προηγούμενων εισόδων** αποθηκεύεται στην εσωτερική κατάσταση του μοντέλου.
    *   Χρησιμοποιούν **οπισθοδιάδοση μέσω του χρόνου (backpropagation-through-time - BPTT)** για εκπαίδευση.
    *   Πιο ευαίσθητα στο πρόβλημα της εξαφανιζόμενης κλίσης από τα CNNs.
    *   **Λειτουργία (Διαφ. 93):** Χρησιμοποιούν το ίδιο σύνολο βαρών `w_h` (για την κρυφή κατάσταση) και `w_x` (για την είσοδο) σε όλα τα χρονικά βήματα. Η κρυφή κατάσταση `h(t)` υπολογίζεται βάσει της `h(t-1)` και της εισόδου `x(t)`.
    *   **Τύποι Εισόδων/Εξόδων (Διαφ. 94):** Ένα-προς-πολλά (Image Captioning), πολλά-προς-ένα (Sentiment Analysis), πολλά-προς-πολλά (Machine Translation).
    *   **Αμφίδρομα RNNs (Bidirectional RNNs) (Διαφ. 95):** Ενσωματώνουν περάσματα προς τα εμπρός και προς τα πίσω μέσω των ακολουθιακών δεδομένων. Η έξοδος μπορεί να εξαρτάται και από μελλοντικά στοιχεία.
    *   **Δίκτυα LSTM (Long Short-Term Memory) (Διαφ. 96-97):**
        *   Παραλλαγή των RNNs που μετριάζει το πρόβλημα εξαφανιζόμενης/εκρηγνυόμενης κλίσης.
        *   Χρησιμοποιούν μια **Κυψέλη Μνήμης (Memory Cell)**.
        *   **Τρεις πύλες (gates)** ελέγχουν τη ροή πληροφορίας:
            *   **Input Gate:** Προστατεύει το τρέχον βήμα από άσχετες εισόδους.
            *   **Output Gate:** Αποτρέπει το τρέχον βήμα από το να περάσει άσχετη πληροφορία σε μεταγενέστερα βήματα.
            *   **Forget Gate:** Περιορίζει την πληροφορία που περνά από τη μια κυψέλη στην επόμενη.
        *   Τα περισσότερα σύγχρονα μοντέλα RNN χρησιμοποιούν είτε LSTM είτε άλλους προηγμένους τύπους (π.χ., GRU).

